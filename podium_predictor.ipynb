{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07fec110",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "# Use Jolpica F1 API (Ergast-compatible endpoint)\n",
    "BASE = \"https://api.jolpi.ca/ergast/f1\"\n",
    "SEASONS = [2022, 2023, 2024, 2025]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c1bfb3",
   "metadata": {},
   "source": [
    "# F1 Podium Predictor\n",
    "\n",
    "## Overview\n",
    "This notebook demonstrates a complete ML pipeline for predicting Formula 1 podium finishes:\n",
    "- **Data Collection**: Fetch F1 race results from Jolpica API\n",
    "- **Data Cleaning**: Handle missing values and remove leakage\n",
    "- **Feature Engineering**: Develop rolling performance metrics\n",
    "- **Baseline Model**: Logistic Regression on raw features\n",
    "- **Final Model**: Gradient Boosting on engineered features\n",
    "- **Evaluation**: Threshold tuning and feature importance analysis\n",
    "\n",
    "---\n",
    "\n",
    "## Part 1: Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "152fc7af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_json(url: str, params=None, sleep_s: float = 0.35, max_retries: int = 8) -> dict:\n",
    "    \"\"\"Fetch JSON with retry/backoff for rate limiting and errors\"\"\"\n",
    "    backoff = 1.0\n",
    "    for attempt in range(1, max_retries + 1):\n",
    "        r = requests.get(\n",
    "            url,\n",
    "            params=params,\n",
    "            timeout=30,\n",
    "            headers={\"Accept\": \"application/json\", \"User-Agent\": \"F1-Podium-Predictor/1.0\"}\n",
    "        )\n",
    "\n",
    "        # Handle rate limiting\n",
    "        if r.status_code == 429:\n",
    "            retry_after = r.headers.get(\"Retry-After\")\n",
    "            wait_s = float(retry_after) if retry_after and retry_after.isdigit() else backoff\n",
    "            print(f\"429 rate limit: waiting {wait_s:.1f}s (attempt {attempt}/{max_retries}) -> {r.url}\")\n",
    "            time.sleep(wait_s)\n",
    "            backoff = min(backoff * 2, 30)\n",
    "            continue\n",
    "\n",
    "        r.raise_for_status()\n",
    "\n",
    "        # Validate JSON response\n",
    "        ctype = (r.headers.get(\"Content-Type\") or \"\").lower()\n",
    "        if \"json\" not in ctype:\n",
    "            preview = r.text[:200].replace(\"\\n\", \" \")\n",
    "            raise ValueError(f\"Non-JSON response from {r.url} | Content-Type={ctype} | Preview={preview}\")\n",
    "\n",
    "        time.sleep(sleep_s)\n",
    "        return r.json()\n",
    "\n",
    "    raise RuntimeError(f\"Failed after {max_retries} retries (last status {r.status_code}) for {url}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7125a847",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rounds_in_season(season: int) -> list[int]:\n",
    "    \"\"\"Returns list of round numbers in a season\"\"\"\n",
    "    url = f\"{BASE}/{season}.json\"\n",
    "    data = get_json(url)\n",
    "    races = data[\"MRData\"][\"RaceTable\"].get(\"Races\", [])\n",
    "    return [int(r[\"round\"]) for r in races]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da487d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_race_results(season: int, round_no: int) -> list[dict]:\n",
    "    \"\"\"Returns one row per driver for a race\"\"\"\n",
    "    url = f\"{BASE}/{season}/{round_no}/results.json\"\n",
    "    data = get_json(url)\n",
    "    races = data[\"MRData\"][\"RaceTable\"].get(\"Races\", [])\n",
    "    if not races:\n",
    "        return []\n",
    "    race = races[0]\n",
    "    circuit = race[\"Circuit\"]\n",
    "    results = race.get(\"Results\", [])\n",
    "\n",
    "    rows = []\n",
    "    for res in results:\n",
    "        driver = res[\"Driver\"]\n",
    "        constructor = res[\"Constructor\"]\n",
    "\n",
    "        # Handle missing or non-numeric finish positions\n",
    "        try:\n",
    "            finish_pos = int(res.get(\"position\"))\n",
    "        except (TypeError, ValueError):\n",
    "            finish_pos = None\n",
    "\n",
    "        rows.append({\n",
    "            \"season\": int(season),\n",
    "            \"round\": int(round_no),\n",
    "            \"raceName\": race.get(\"raceName\"),\n",
    "            \"date\": race.get(\"date\"),\n",
    "            \"circuitId\": circuit.get(\"circuitId\"),\n",
    "            \"circuitName\": circuit.get(\"circuitName\"),\n",
    "            \"driverId\": driver.get(\"driverId\"),\n",
    "            \"driverCode\": driver.get(\"code\"),\n",
    "            \"driverGivenName\": driver.get(\"givenName\"),\n",
    "            \"driverFamilyName\": driver.get(\"familyName\"),\n",
    "            \"constructorId\": constructor.get(\"constructorId\"),\n",
    "            \"constructorName\": constructor.get(\"name\"),\n",
    "            \"grid\": int(res[\"grid\"]) if res.get(\"grid\") not in (None, \"\") else None,\n",
    "            \"finish_position\": finish_pos,\n",
    "            \"points\": float(res[\"points\"]) if res.get(\"points\") not in (None, \"\") else None,\n",
    "            \"laps\": int(res[\"laps\"]) if res.get(\"laps\") not in (None, \"\") else None,\n",
    "            \"status\": res.get(\"status\"),\n",
    "        })\n",
    "    return rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5dd52f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_qualifying(season: int, round_no: int) -> dict:\n",
    "    \"\"\"Returns dict mapping driverId to qualifying position\"\"\"\n",
    "    url = f\"{BASE}/{season}/{round_no}/qualifying.json\"\n",
    "    data = get_json(url)\n",
    "    races = data[\"MRData\"][\"RaceTable\"].get(\"Races\", [])\n",
    "    if not races:\n",
    "        return {}\n",
    "    q = races[0].get(\"QualifyingResults\", [])\n",
    "    out = {}\n",
    "    for row in q:\n",
    "        try:\n",
    "            out[row[\"Driver\"][\"driverId\"]] = int(row[\"position\"])\n",
    "        except Exception:\n",
    "            pass\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "245b01ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Season 2022 rounds found: 22\n",
      "Season 2023 rounds found: 22\n",
      "Season 2024 rounds found: 24\n",
      "429 rate limit: waiting 1.0s (attempt 1/8) -> https://api.jolpi.ca/ergast/f1/2024/1/qualifying.json\n",
      "429 rate limit: waiting 1.0s (attempt 1/8) -> https://api.jolpi.ca/ergast/f1/2024/2/results.json\n",
      "429 rate limit: waiting 1.0s (attempt 1/8) -> https://api.jolpi.ca/ergast/f1/2024/2/qualifying.json\n",
      "429 rate limit: waiting 1.0s (attempt 1/8) -> https://api.jolpi.ca/ergast/f1/2024/3/results.json\n",
      "429 rate limit: waiting 1.0s (attempt 1/8) -> https://api.jolpi.ca/ergast/f1/2024/3/qualifying.json\n",
      "429 rate limit: waiting 2.0s (attempt 2/8) -> https://api.jolpi.ca/ergast/f1/2024/3/qualifying.json\n",
      "429 rate limit: waiting 1.0s (attempt 1/8) -> https://api.jolpi.ca/ergast/f1/2024/4/qualifying.json\n",
      "429 rate limit: waiting 2.0s (attempt 2/8) -> https://api.jolpi.ca/ergast/f1/2024/4/qualifying.json\n",
      "429 rate limit: waiting 1.0s (attempt 1/8) -> https://api.jolpi.ca/ergast/f1/2024/5/qualifying.json\n",
      "429 rate limit: waiting 2.0s (attempt 2/8) -> https://api.jolpi.ca/ergast/f1/2024/5/qualifying.json\n",
      "429 rate limit: waiting 1.0s (attempt 1/8) -> https://api.jolpi.ca/ergast/f1/2024/6/qualifying.json\n",
      "429 rate limit: waiting 2.0s (attempt 2/8) -> https://api.jolpi.ca/ergast/f1/2024/6/qualifying.json\n",
      "429 rate limit: waiting 1.0s (attempt 1/8) -> https://api.jolpi.ca/ergast/f1/2024/7/results.json\n",
      "429 rate limit: waiting 1.0s (attempt 1/8) -> https://api.jolpi.ca/ergast/f1/2024/7/qualifying.json\n",
      "429 rate limit: waiting 1.0s (attempt 1/8) -> https://api.jolpi.ca/ergast/f1/2024/8/results.json\n",
      "429 rate limit: waiting 1.0s (attempt 1/8) -> https://api.jolpi.ca/ergast/f1/2024/8/qualifying.json\n",
      "429 rate limit: waiting 2.0s (attempt 2/8) -> https://api.jolpi.ca/ergast/f1/2024/8/qualifying.json\n",
      "429 rate limit: waiting 1.0s (attempt 1/8) -> https://api.jolpi.ca/ergast/f1/2024/9/results.json\n",
      "429 rate limit: waiting 1.0s (attempt 1/8) -> https://api.jolpi.ca/ergast/f1/2024/9/qualifying.json\n",
      "429 rate limit: waiting 1.0s (attempt 1/8) -> https://api.jolpi.ca/ergast/f1/2024/10/results.json\n",
      "429 rate limit: waiting 1.0s (attempt 1/8) -> https://api.jolpi.ca/ergast/f1/2024/10/qualifying.json\n",
      "429 rate limit: waiting 2.0s (attempt 2/8) -> https://api.jolpi.ca/ergast/f1/2024/10/qualifying.json\n",
      "429 rate limit: waiting 1.0s (attempt 1/8) -> https://api.jolpi.ca/ergast/f1/2024/11/qualifying.json\n",
      "429 rate limit: waiting 2.0s (attempt 2/8) -> https://api.jolpi.ca/ergast/f1/2024/11/qualifying.json\n",
      "429 rate limit: waiting 1.0s (attempt 1/8) -> https://api.jolpi.ca/ergast/f1/2024/12/results.json\n",
      "429 rate limit: waiting 1.0s (attempt 1/8) -> https://api.jolpi.ca/ergast/f1/2024/12/qualifying.json\n",
      "429 rate limit: waiting 1.0s (attempt 1/8) -> https://api.jolpi.ca/ergast/f1/2024/13/results.json\n",
      "429 rate limit: waiting 1.0s (attempt 1/8) -> https://api.jolpi.ca/ergast/f1/2024/13/qualifying.json\n",
      "429 rate limit: waiting 2.0s (attempt 2/8) -> https://api.jolpi.ca/ergast/f1/2024/13/qualifying.json\n",
      "429 rate limit: waiting 1.0s (attempt 1/8) -> https://api.jolpi.ca/ergast/f1/2024/14/qualifying.json\n",
      "429 rate limit: waiting 2.0s (attempt 2/8) -> https://api.jolpi.ca/ergast/f1/2024/14/qualifying.json\n",
      "429 rate limit: waiting 1.0s (attempt 1/8) -> https://api.jolpi.ca/ergast/f1/2024/15/results.json\n",
      "429 rate limit: waiting 1.0s (attempt 1/8) -> https://api.jolpi.ca/ergast/f1/2024/15/qualifying.json\n",
      "429 rate limit: waiting 1.0s (attempt 1/8) -> https://api.jolpi.ca/ergast/f1/2024/16/results.json\n",
      "429 rate limit: waiting 1.0s (attempt 1/8) -> https://api.jolpi.ca/ergast/f1/2024/16/qualifying.json\n",
      "429 rate limit: waiting 2.0s (attempt 2/8) -> https://api.jolpi.ca/ergast/f1/2024/16/qualifying.json\n",
      "429 rate limit: waiting 1.0s (attempt 1/8) -> https://api.jolpi.ca/ergast/f1/2024/17/qualifying.json\n",
      "429 rate limit: waiting 2.0s (attempt 2/8) -> https://api.jolpi.ca/ergast/f1/2024/17/qualifying.json\n",
      "429 rate limit: waiting 1.0s (attempt 1/8) -> https://api.jolpi.ca/ergast/f1/2024/18/results.json\n",
      "429 rate limit: waiting 1.0s (attempt 1/8) -> https://api.jolpi.ca/ergast/f1/2024/18/qualifying.json\n",
      "429 rate limit: waiting 1.0s (attempt 1/8) -> https://api.jolpi.ca/ergast/f1/2024/19/results.json\n",
      "429 rate limit: waiting 1.0s (attempt 1/8) -> https://api.jolpi.ca/ergast/f1/2024/19/qualifying.json\n",
      "429 rate limit: waiting 2.0s (attempt 2/8) -> https://api.jolpi.ca/ergast/f1/2024/19/qualifying.json\n",
      "429 rate limit: waiting 1.0s (attempt 1/8) -> https://api.jolpi.ca/ergast/f1/2024/20/results.json\n",
      "429 rate limit: waiting 1.0s (attempt 1/8) -> https://api.jolpi.ca/ergast/f1/2024/20/qualifying.json\n",
      "429 rate limit: waiting 1.0s (attempt 1/8) -> https://api.jolpi.ca/ergast/f1/2024/21/results.json\n",
      "429 rate limit: waiting 1.0s (attempt 1/8) -> https://api.jolpi.ca/ergast/f1/2024/21/qualifying.json\n",
      "429 rate limit: waiting 2.0s (attempt 2/8) -> https://api.jolpi.ca/ergast/f1/2024/21/qualifying.json\n",
      "429 rate limit: waiting 1.0s (attempt 1/8) -> https://api.jolpi.ca/ergast/f1/2024/22/results.json\n",
      "429 rate limit: waiting 1.0s (attempt 1/8) -> https://api.jolpi.ca/ergast/f1/2024/22/qualifying.json\n",
      "429 rate limit: waiting 1.0s (attempt 1/8) -> https://api.jolpi.ca/ergast/f1/2024/23/results.json\n",
      "429 rate limit: waiting 1.0s (attempt 1/8) -> https://api.jolpi.ca/ergast/f1/2024/23/qualifying.json\n",
      "429 rate limit: waiting 2.0s (attempt 2/8) -> https://api.jolpi.ca/ergast/f1/2024/23/qualifying.json\n",
      "429 rate limit: waiting 1.0s (attempt 1/8) -> https://api.jolpi.ca/ergast/f1/2024/24/qualifying.json\n",
      "429 rate limit: waiting 2.0s (attempt 2/8) -> https://api.jolpi.ca/ergast/f1/2024/24/qualifying.json\n",
      "429 rate limit: waiting 1.0s (attempt 1/8) -> https://api.jolpi.ca/ergast/f1/2025.json\n",
      "Season 2025 rounds found: 24\n",
      "429 rate limit: waiting 1.0s (attempt 1/8) -> https://api.jolpi.ca/ergast/f1/2025/1/results.json\n",
      "429 rate limit: waiting 1.0s (attempt 1/8) -> https://api.jolpi.ca/ergast/f1/2025/1/qualifying.json\n",
      "429 rate limit: waiting 2.0s (attempt 2/8) -> https://api.jolpi.ca/ergast/f1/2025/1/qualifying.json\n",
      "429 rate limit: waiting 1.0s (attempt 1/8) -> https://api.jolpi.ca/ergast/f1/2025/2/qualifying.json\n",
      "429 rate limit: waiting 2.0s (attempt 2/8) -> https://api.jolpi.ca/ergast/f1/2025/2/qualifying.json\n",
      "429 rate limit: waiting 1.0s (attempt 1/8) -> https://api.jolpi.ca/ergast/f1/2025/3/results.json\n",
      "429 rate limit: waiting 1.0s (attempt 1/8) -> https://api.jolpi.ca/ergast/f1/2025/3/qualifying.json\n",
      "429 rate limit: waiting 1.0s (attempt 1/8) -> https://api.jolpi.ca/ergast/f1/2025/4/results.json\n",
      "429 rate limit: waiting 1.0s (attempt 1/8) -> https://api.jolpi.ca/ergast/f1/2025/4/qualifying.json\n",
      "429 rate limit: waiting 2.0s (attempt 2/8) -> https://api.jolpi.ca/ergast/f1/2025/4/qualifying.json\n",
      "429 rate limit: waiting 1.0s (attempt 1/8) -> https://api.jolpi.ca/ergast/f1/2025/5/results.json\n",
      "429 rate limit: waiting 1.0s (attempt 1/8) -> https://api.jolpi.ca/ergast/f1/2025/5/qualifying.json\n",
      "429 rate limit: waiting 1.0s (attempt 1/8) -> https://api.jolpi.ca/ergast/f1/2025/6/results.json\n",
      "429 rate limit: waiting 2.0s (attempt 2/8) -> https://api.jolpi.ca/ergast/f1/2025/6/results.json\n",
      "429 rate limit: waiting 1.0s (attempt 1/8) -> https://api.jolpi.ca/ergast/f1/2025/7/results.json\n",
      "429 rate limit: waiting 2.0s (attempt 2/8) -> https://api.jolpi.ca/ergast/f1/2025/7/results.json\n",
      "429 rate limit: waiting 1.0s (attempt 1/8) -> https://api.jolpi.ca/ergast/f1/2025/8/results.json\n",
      "429 rate limit: waiting 2.0s (attempt 2/8) -> https://api.jolpi.ca/ergast/f1/2025/8/results.json\n",
      "429 rate limit: waiting 1.0s (attempt 1/8) -> https://api.jolpi.ca/ergast/f1/2025/9/results.json\n",
      "429 rate limit: waiting 2.0s (attempt 2/8) -> https://api.jolpi.ca/ergast/f1/2025/9/results.json\n",
      "429 rate limit: waiting 1.0s (attempt 1/8) -> https://api.jolpi.ca/ergast/f1/2025/9/qualifying.json\n",
      "429 rate limit: waiting 1.0s (attempt 1/8) -> https://api.jolpi.ca/ergast/f1/2025/10/results.json\n",
      "429 rate limit: waiting 1.0s (attempt 1/8) -> https://api.jolpi.ca/ergast/f1/2025/10/qualifying.json\n",
      "429 rate limit: waiting 1.0s (attempt 1/8) -> https://api.jolpi.ca/ergast/f1/2025/11/results.json\n",
      "429 rate limit: waiting 2.0s (attempt 2/8) -> https://api.jolpi.ca/ergast/f1/2025/11/results.json\n",
      "429 rate limit: waiting 1.0s (attempt 1/8) -> https://api.jolpi.ca/ergast/f1/2025/12/results.json\n",
      "429 rate limit: waiting 2.0s (attempt 2/8) -> https://api.jolpi.ca/ergast/f1/2025/12/results.json\n",
      "429 rate limit: waiting 1.0s (attempt 1/8) -> https://api.jolpi.ca/ergast/f1/2025/12/qualifying.json\n",
      "429 rate limit: waiting 1.0s (attempt 1/8) -> https://api.jolpi.ca/ergast/f1/2025/13/results.json\n",
      "429 rate limit: waiting 1.0s (attempt 1/8) -> https://api.jolpi.ca/ergast/f1/2025/13/qualifying.json\n",
      "429 rate limit: waiting 1.0s (attempt 1/8) -> https://api.jolpi.ca/ergast/f1/2025/14/results.json\n",
      "429 rate limit: waiting 2.0s (attempt 2/8) -> https://api.jolpi.ca/ergast/f1/2025/14/results.json\n",
      "429 rate limit: waiting 1.0s (attempt 1/8) -> https://api.jolpi.ca/ergast/f1/2025/15/results.json\n",
      "429 rate limit: waiting 2.0s (attempt 2/8) -> https://api.jolpi.ca/ergast/f1/2025/15/results.json\n",
      "429 rate limit: waiting 1.0s (attempt 1/8) -> https://api.jolpi.ca/ergast/f1/2025/16/results.json\n",
      "429 rate limit: waiting 2.0s (attempt 2/8) -> https://api.jolpi.ca/ergast/f1/2025/16/results.json\n",
      "429 rate limit: waiting 1.0s (attempt 1/8) -> https://api.jolpi.ca/ergast/f1/2025/17/results.json\n",
      "429 rate limit: waiting 2.0s (attempt 2/8) -> https://api.jolpi.ca/ergast/f1/2025/17/results.json\n",
      "429 rate limit: waiting 1.0s (attempt 1/8) -> https://api.jolpi.ca/ergast/f1/2025/17/qualifying.json\n",
      "429 rate limit: waiting 1.0s (attempt 1/8) -> https://api.jolpi.ca/ergast/f1/2025/18/results.json\n",
      "429 rate limit: waiting 1.0s (attempt 1/8) -> https://api.jolpi.ca/ergast/f1/2025/18/qualifying.json\n",
      "429 rate limit: waiting 1.0s (attempt 1/8) -> https://api.jolpi.ca/ergast/f1/2025/19/results.json\n",
      "429 rate limit: waiting 2.0s (attempt 2/8) -> https://api.jolpi.ca/ergast/f1/2025/19/results.json\n",
      "429 rate limit: waiting 1.0s (attempt 1/8) -> https://api.jolpi.ca/ergast/f1/2025/19/qualifying.json\n",
      "429 rate limit: waiting 1.0s (attempt 1/8) -> https://api.jolpi.ca/ergast/f1/2025/20/results.json\n",
      "429 rate limit: waiting 1.0s (attempt 1/8) -> https://api.jolpi.ca/ergast/f1/2025/20/qualifying.json\n",
      "429 rate limit: waiting 1.0s (attempt 1/8) -> https://api.jolpi.ca/ergast/f1/2025/21/results.json\n",
      "429 rate limit: waiting 2.0s (attempt 2/8) -> https://api.jolpi.ca/ergast/f1/2025/21/results.json\n",
      "429 rate limit: waiting 1.0s (attempt 1/8) -> https://api.jolpi.ca/ergast/f1/2025/22/results.json\n",
      "429 rate limit: waiting 2.0s (attempt 2/8) -> https://api.jolpi.ca/ergast/f1/2025/22/results.json\n",
      "429 rate limit: waiting 1.0s (attempt 1/8) -> https://api.jolpi.ca/ergast/f1/2025/23/results.json\n",
      "429 rate limit: waiting 2.0s (attempt 2/8) -> https://api.jolpi.ca/ergast/f1/2025/23/results.json\n",
      "429 rate limit: waiting 1.0s (attempt 1/8) -> https://api.jolpi.ca/ergast/f1/2025/24/results.json\n",
      "429 rate limit: waiting 2.0s (attempt 2/8) -> https://api.jolpi.ca/ergast/f1/2025/24/results.json\n"
     ]
    }
   ],
   "source": [
    "all_rows = []\n",
    "\n",
    "for season in SEASONS:\n",
    "    rounds = get_rounds_in_season(season)\n",
    "    print(f\"Season {season} rounds found: {len(rounds)}\")\n",
    "\n",
    "    for rnd in rounds:\n",
    "        rows = get_race_results(season, rnd)\n",
    "        if not rows:\n",
    "            continue\n",
    "\n",
    "        # Get qualifying results (may be missing for some races)\n",
    "        try:\n",
    "            q_map = get_qualifying(season, rnd)\n",
    "        except Exception as e:\n",
    "            print(f\"Qualifying unavailable for {season} round {rnd}: {e}\")\n",
    "            q_map = {}\n",
    "\n",
    "        # Add qualifying position and podium label\n",
    "        for r in rows:\n",
    "            r[\"qual_position\"] = q_map.get(r[\"driverId\"])\n",
    "            r[\"podium\"] = 1 if (r[\"finish_position\"] is not None and r[\"finish_position\"] <= 3) else 0\n",
    "\n",
    "        all_rows.extend(rows)\n",
    "\n",
    "if not all_rows:\n",
    "    raise RuntimeError(\"No rows collected. Check internet access and that the API is reachable.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "128014b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: jolpica_podium_dataset_2022_2025.csv rows: 1838\n"
     ]
    }
   ],
   "source": [
    "# Build dataframe and handle missing data\n",
    "df_raw = pd.DataFrame(all_rows)\n",
    "\n",
    "df_raw = df_raw.dropna(subset=[\"grid\", \"finish_position\"]).copy()\n",
    "df_raw[\"qual_position\"] = df_raw[\"qual_position\"].fillna(df_raw[\"grid\"])\n",
    "\n",
    "# Save dataset\n",
    "out_path = \"jolpica_podium_dataset_2022_2025.csv\"\n",
    "df_raw.to_csv(out_path, index=False)\n",
    "print(\"Saved:\", out_path, \"rows:\", len(df_raw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "096c3736",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "season              0\n",
      "round               0\n",
      "raceName            0\n",
      "date                0\n",
      "circuitId           0\n",
      "circuitName         0\n",
      "driverId            0\n",
      "driverCode          0\n",
      "driverGivenName     0\n",
      "driverFamilyName    0\n",
      "constructorId       0\n",
      "constructorName     0\n",
      "grid                0\n",
      "finish_position     0\n",
      "points              0\n",
      "laps                0\n",
      "status              0\n",
      "qual_position       0\n",
      "podium              0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "print(df_raw.isna().sum().sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6850017d",
   "metadata": {},
   "source": [
    "## Part 2: Data Cleaning & Preprocessing\n",
    "\n",
    "Remove rows with missing values, filter invalid positions, and prepare dataset for modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b9d94e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert numeric columns to proper types\n",
    "numeric_cols = [\"season\", \"round\", \"grid\", \"qual_position\", \"finish_position\", \"points\", \"laps\"]\n",
    "\n",
    "for col in numeric_cols:\n",
    "    if col in df_raw.columns:\n",
    "        df_raw[col] = pd.to_numeric(df_raw[col], errors=\"coerce\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "65be25e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out invalid positions (DNS, DNF, disqualifications)\n",
    "df_raw = df_raw[df_raw[\"grid\"].between(1, 20)]\n",
    "df_raw = df_raw[df_raw[\"finish_position\"].between(1, 20)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "286bdfa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "podium\n",
      "0    0.848601\n",
      "1    0.151399\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Check class balance of target variable\n",
    "print(df_raw[\"podium\"].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "12d91536",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select features for modeling\n",
    "model_df = df_raw[[\n",
    "    \"season\",\n",
    "    \"round\",\n",
    "    \"circuitId\",\n",
    "    \"driverId\",\n",
    "    \"constructorId\",\n",
    "    \"grid\",\n",
    "    \"qual_position\",\n",
    "    \"podium\"\n",
    "]].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f48eb1da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean dataset saved.\n"
     ]
    }
   ],
   "source": [
    "# Save cleaned dataset\n",
    "model_df.to_csv(\"clean_podium_dataset.csv\", index=False)\n",
    "print(\"Clean dataset saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "75cc27b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset for feature engineering\n",
    "df_full = pd.read_csv(\"jolpica_podium_dataset_2022_2025.csv\").sort_values([\"season\",\"round\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9154f1aa",
   "metadata": {},
   "source": [
    "## Part 3: Feature Engineering\n",
    "\n",
    "Create rolling performance metrics and momentum features to capture historical context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "734ae008",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rolling averages (group-safe) - exclude current race with shift(1)\n",
    "df_full[\"driver_points_last3\"] = (\n",
    "    df_full.groupby(\"driverId\")[\"points\"]\n",
    "    .apply(lambda s: s.shift(1).rolling(3, min_periods=1).mean())\n",
    "    .reset_index(level=0, drop=True)\n",
    ")\n",
    "\n",
    "df_full[\"constructor_points_last3\"] = (\n",
    "    df_full.groupby(\"constructorId\")[\"points\"]\n",
    "    .apply(lambda s: s.shift(1).rolling(3, min_periods=1).mean())\n",
    "    .reset_index(level=0, drop=True)\n",
    ")\n",
    "\n",
    "df_full[\"driver_podiums_last3\"] = (\n",
    "    df_full.groupby(\"driverId\")[\"podium\"]\n",
    "    .apply(lambda s: s.shift(1).rolling(3, min_periods=1).mean())\n",
    "    .reset_index(level=0, drop=True)\n",
    ")\n",
    "\n",
    "df_full[\"driver_finishpos_last3\"] = (\n",
    "    df_full.groupby(\"driverId\")[\"finish_position\"]\n",
    "    .apply(lambda s: s.shift(1).rolling(3, min_periods=1).mean())\n",
    "    .reset_index(level=0, drop=True)\n",
    ")\n",
    "\n",
    "df_full[\"constructor_podiums_last3\"] = (\n",
    "    df_full.groupby(\"constructorId\")[\"podium\"]\n",
    "    .apply(lambda s: s.shift(1).rolling(3, min_periods=1).mean())\n",
    "    .reset_index(level=0, drop=True)\n",
    ")\n",
    "\n",
    "df_full[\"grid_inverse\"] = 1 / df_full[\"grid\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "55aa6b11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_feat shape: (1838, 14)\n",
      "df_feat columns: ['season', 'round', 'circuitId', 'driverId', 'constructorId', 'grid', 'qual_position', 'driver_points_last3', 'constructor_points_last3', 'driver_podiums_last3', 'driver_finishpos_last3', 'constructor_podiums_last3', 'grid_inverse', 'podium']\n",
      "Saved feature_engineered_dataset.csv\n"
     ]
    }
   ],
   "source": [
    "# Extract the complete feature set from df_full\n",
    "df_feat = df_full[[\n",
    "    \"season\",\"round\",\"circuitId\",\"driverId\",\"constructorId\",\n",
    "    \"grid\",\"qual_position\",\n",
    "    \"driver_points_last3\",\"constructor_points_last3\",\"driver_podiums_last3\",\n",
    "    \"driver_finishpos_last3\",\"constructor_podiums_last3\",\"grid_inverse\",\n",
    "    \"podium\"\n",
    "]].copy()\n",
    "\n",
    "# Fill NaNs (early races etc.)\n",
    "fill_cols = [\n",
    "    \"driver_points_last3\",\"constructor_points_last3\",\"driver_podiums_last3\",\n",
    "    \"driver_finishpos_last3\",\"constructor_podiums_last3\",\"grid_inverse\"\n",
    "]\n",
    "df_feat[fill_cols] = df_feat[fill_cols].fillna(0)\n",
    "\n",
    "print(\"df_feat shape:\", df_feat.shape)\n",
    "print(\"df_feat columns:\", df_feat.columns.tolist())\n",
    "\n",
    "# Save feature-engineered dataset\n",
    "df_feat.to_csv(\"feature_engineered_dataset.csv\", index=False)\n",
    "print(\"Saved feature_engineered_dataset.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c171d0",
   "metadata": {},
   "source": [
    "Baseline Model (Raw Predictors)\n",
    "Logistic Regression trained using basic race features without rolling performance metrics.\n",
    "Purpose: Establish benchmark performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d00341ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, roc_auc_score, confusion_matrix, precision_score, recall_score, f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c88990",
   "metadata": {},
   "source": [
    "## Part 4: Baseline Model — Logistic Regression (Raw Features)\n",
    "\n",
    "**Purpose**: Establish benchmark performance using basic race features (grid, qualifying position, team).\n",
    "\n",
    "**Hypothesis**: Raw features alone provide limited predictive power for podium finishes.\n",
    "\n",
    "This baseline demonstrates the *controlled experiment*: same data split (2022-2024 train, 2025 test), same evaluation metrics. It justifies the value of engineered features by direct comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e3dc3663",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/test split: 2022-2024 for training, 2025 for testing\n",
    "df_clean = pd.read_csv(\"jolpica_podium_dataset_2022_2025.csv\")\n",
    "\n",
    "train_df = df_clean[df_clean[\"season\"].isin([2022, 2023, 2024])].copy()\n",
    "test_df  = df_clean[df_clean[\"season\"] == 2025].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bd486cb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Model (Logistic Regression) - Evaluating thresholds...\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# Separate categorical and numeric features\n",
    "cat_cols = [\"circuitId\",\"constructorId\",\"driverId\"]\n",
    "num_cols = [\"season\",\"round\",\"grid\",\"qual_position\"]\n",
    "\n",
    "# One-hot encode categoricals, pass through numerics\n",
    "prep = ColumnTransformer([\n",
    "    (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), cat_cols),\n",
    "    (\"num\", \"passthrough\", num_cols),\n",
    "])\n",
    "\n",
    "# Build pipeline with preprocessing and logistic regression\n",
    "model = Pipeline([\n",
    "    (\"prep\", prep),\n",
    "    (\"clf\", LogisticRegression(max_iter=3000, class_weight=\"balanced\"))\n",
    "])\n",
    "\n",
    "# Train and evaluate baseline model\n",
    "features = num_cols + cat_cols\n",
    "X_train, y_train = train_df[features], train_df[\"podium\"]\n",
    "X_test,  y_test  = test_df[features],  test_df[\"podium\"]\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"Baseline Model (Logistic Regression) - Evaluating thresholds...\")\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e375a4ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold=0.10 | Precision=0.327 | Recall=0.972 | F1=0.490\n",
      "Threshold=0.15 | Precision=0.345 | Recall=0.972 | F1=0.509\n",
      "Threshold=0.20 | Precision=0.375 | Recall=0.958 | F1=0.539\n",
      "Threshold=0.25 | Precision=0.406 | Recall=0.958 | F1=0.570\n",
      "Threshold=0.30 | Precision=0.422 | Recall=0.944 | F1=0.584\n",
      "Threshold=0.35 | Precision=0.429 | Recall=0.931 | F1=0.588\n",
      "Threshold=0.40 | Precision=0.456 | Recall=0.931 | F1=0.612\n",
      "Threshold=0.45 | Precision=0.475 | Recall=0.917 | F1=0.626\n",
      "Threshold=0.50 | Precision=0.493 | Recall=0.917 | F1=0.641\n",
      "Threshold=0.55 | Precision=0.528 | Recall=0.903 | F1=0.667\n",
      "Threshold=0.60 | Precision=0.542 | Recall=0.889 | F1=0.674\n",
      "Threshold=0.65 | Precision=0.570 | Recall=0.847 | F1=0.682\n",
      "Threshold=0.70 | Precision=0.613 | Recall=0.792 | F1=0.691\n",
      "Threshold=0.75 | Precision=0.684 | Recall=0.750 | F1=0.715\n",
      "Threshold=0.80 | Precision=0.716 | Recall=0.667 | F1=0.691\n",
      "Threshold=0.85 | Precision=0.688 | Recall=0.458 | F1=0.550\n"
     ]
    }
   ],
   "source": [
    "thresholds = np.arange(0.1, 0.9, 0.05)\n",
    "\n",
    "results = []\n",
    "\n",
    "for t in thresholds:\n",
    "    pred_t = (proba >= t).astype(int)\n",
    "\n",
    "    precision = precision_score(y_test, pred_t)\n",
    "    recall = recall_score(y_test, pred_t)\n",
    "    f1 = f1_score(y_test, pred_t)\n",
    "\n",
    "    results.append((t, precision, recall, f1))\n",
    "\n",
    "for r in results:\n",
    "    print(f\"Threshold={r[0]:.2f} | Precision={r[1]:.3f} | Recall={r[2]:.3f} | F1={r[3]:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dc482ee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix (t=0.75):\n",
      "[[382  25]\n",
      " [ 18  54]]\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.955     0.939     0.947       407\n",
      "           1      0.684     0.750     0.715        72\n",
      "\n",
      "    accuracy                          0.910       479\n",
      "   macro avg      0.819     0.844     0.831       479\n",
      "weighted avg      0.914     0.910     0.912       479\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_t = 0.75\n",
    "pred_best = (proba >= best_t).astype(int)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "print(\"Confusion matrix (t=0.75):\")\n",
    "print(confusion_matrix(y_test, pred_best))\n",
    "\n",
    "print(\"\\nClassification report:\")\n",
    "print(classification_report(y_test, pred_best, digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d947d46",
   "metadata": {},
   "source": [
    "Final Model (Feature-Engineered Predictors)\n",
    "Gradient Boosting classifier trained using rolling performance and momentum features.\n",
    "Purpose: Evaluate predictive gains from feature engineering.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5b1faf17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "GradientBoostingClassifier Results\n",
      "==================================================\n",
      "ROC AUC: 0.955\n",
      "Best Threshold (F1): 0.30\n",
      "Precision: 0.678 | Recall: 0.847 | F1: 0.753\n",
      "\n",
      "Confusion Matrix:\n",
      "[[378  29]\n",
      " [ 11  61]]\n"
     ]
    }
   ],
   "source": [
    "# Import additional classifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# Load engineered features\n",
    "df_feat = pd.read_csv(\"feature_engineered_dataset.csv\")\n",
    "\n",
    "# Time-aware split\n",
    "train_df_feat = df_feat[df_feat[\"season\"].isin([2022, 2023, 2024])].copy()\n",
    "test_df_feat  = df_feat[df_feat[\"season\"] == 2025].copy()\n",
    "\n",
    "# Extract features\n",
    "target = \"podium\"\n",
    "features_eng = [c for c in df_feat.columns if c != target]\n",
    "\n",
    "X_train_eng, y_train_eng = train_df_feat[features_eng], train_df_feat[target]\n",
    "X_test_eng,  y_test_eng  = test_df_feat[features_eng],  test_df_feat[target]\n",
    "\n",
    "# Handle infinite values\n",
    "X_train_eng = X_train_eng.replace([np.inf, -np.inf], np.nan).fillna(0)\n",
    "X_test_eng = X_test_eng.replace([np.inf, -np.inf], np.nan).fillna(0)\n",
    "\n",
    "# Categorical + numeric columns\n",
    "cat_cols_eng = [\"circuitId\", \"constructorId\", \"driverId\"]\n",
    "num_cols_eng = [c for c in features_eng if c not in cat_cols_eng]\n",
    "\n",
    "# Train GradientBoostingClassifier (use engineered features)\n",
    "gb_model = Pipeline([\n",
    "    (\"prep\", ColumnTransformer([\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), cat_cols_eng),\n",
    "        (\"num\", \"passthrough\", num_cols_eng),\n",
    "    ])),\n",
    "    (\"clf\", GradientBoostingClassifier(random_state=42, n_estimators=100))\n",
    "])\n",
    "\n",
    "gb_model.fit(X_train_eng, y_train_eng)\n",
    "\n",
    "# Get predictions\n",
    "proba = gb_model.predict_proba(X_test_eng)[:, 1]\n",
    "\n",
    "# Find best threshold\n",
    "def best_threshold(y_true, proba):\n",
    "    thresholds = np.arange(0.10, 0.91, 0.05)\n",
    "    best = (0.50, -1, None)  # (t, best_f1, (prec, rec))\n",
    "    for t in thresholds:\n",
    "        pred = (proba >= t).astype(int)\n",
    "        p = precision_score(y_true, pred, zero_division=0)\n",
    "        r = recall_score(y_true, pred, zero_division=0)\n",
    "        f = f1_score(y_true, pred, zero_division=0)\n",
    "        if f > best[1]:\n",
    "            best = (t, f, (p, r))\n",
    "    return best\n",
    "\n",
    "best_t, best_f1, (best_p, best_r) = best_threshold(y_test_eng, proba)\n",
    "pred_best = (proba >= best_t).astype(int)\n",
    "\n",
    "# Results\n",
    "auc = roc_auc_score(y_test_eng, proba)\n",
    "cm = confusion_matrix(y_test_eng, pred_best)\n",
    "\n",
    "print(\"\\nGradientBoostingClassifier Results\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"ROC AUC: {auc:.3f}\")\n",
    "print(f\"Best Threshold (F1): {best_t:.2f}\")\n",
    "print(f\"Precision: {best_p:.3f} | Recall: {best_r:.3f} | F1: {best_f1:.3f}\")\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "8bba73e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved final_gb_model.joblib\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(gb_model, \"final_gb_model.joblib\")\n",
    "\n",
    "print(\"Saved final_gb_model.joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce04e51",
   "metadata": {},
   "source": [
    "## Part 5: Final Model — Gradient Boosting (Engineered Features)\n",
    "\n",
    "**Purpose**: Evaluate performance improvements using domain-informed rolling performance metrics.\n",
    "\n",
    "**Hypothesis**: Rolling features (driver/team points last 3 races, podium rate, finish position trends) provide significant predictive power.\n",
    "\n",
    "**Outcome**: Compare ROC AUC and optimal threshold metrics against baseline to quantify feature engineering value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4b4c9bd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>grid_inverse</td>\n",
       "      <td>0.376674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>qual_position</td>\n",
       "      <td>0.193228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>driver_points_last3</td>\n",
       "      <td>0.093352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>constructor_points_last3</td>\n",
       "      <td>0.061198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>driver_finishpos_last3</td>\n",
       "      <td>0.042868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>grid</td>\n",
       "      <td>0.035511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>driverId_max_verstappen</td>\n",
       "      <td>0.019312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>constructor_podiums_last3</td>\n",
       "      <td>0.019216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>round</td>\n",
       "      <td>0.015974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>driver_podiums_last3</td>\n",
       "      <td>0.014931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>circuitId_silverstone</td>\n",
       "      <td>0.014110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>driverId_sainz</td>\n",
       "      <td>0.010662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>driverId_russell</td>\n",
       "      <td>0.010409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>circuitId_interlagos</td>\n",
       "      <td>0.009132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>circuitId_albert_park</td>\n",
       "      <td>0.008584</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      feature  importance\n",
       "74               grid_inverse    0.376674\n",
       "68              qual_position    0.193228\n",
       "69        driver_points_last3    0.093352\n",
       "70   constructor_points_last3    0.061198\n",
       "72     driver_finishpos_last3    0.042868\n",
       "67                       grid    0.035511\n",
       "51    driverId_max_verstappen    0.019312\n",
       "73  constructor_podiums_last3    0.019216\n",
       "66                      round    0.015974\n",
       "71       driver_podiums_last3    0.014931\n",
       "18      circuitId_silverstone    0.014110\n",
       "59             driverId_sainz    0.010662\n",
       "58           driverId_russell    0.010409\n",
       "7        circuitId_interlagos    0.009132\n",
       "0       circuitId_albert_park    0.008584"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get feature names after preprocessing\n",
    "ohe = gb_model.named_steps[\"prep\"].named_transformers_[\"cat\"]\n",
    "cat_feature_names = ohe.get_feature_names_out(cat_cols_eng)\n",
    "\n",
    "all_feature_names = np.concatenate([cat_feature_names, num_cols_eng])\n",
    "\n",
    "# Get importance values\n",
    "importances = gb_model.named_steps[\"clf\"].feature_importances_\n",
    "\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    \"feature\": all_feature_names,\n",
    "    \"importance\": importances\n",
    "}).sort_values(\"importance\", ascending=False)\n",
    "\n",
    "feature_importance_df.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c43c2a",
   "metadata": {},
   "source": [
    "## Part 6: Interpretability & Feature Importance\n",
    "\n",
    "Analyze which features drive the model's predictions. This demonstrates that the engineered rolling metrics are indeed the most impactful predictors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "591385e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "group\n",
       "Grid advantage (inverse)      0.376674\n",
       "Qualifying position           0.193228\n",
       "Driver recent points          0.093352\n",
       "Circuit                       0.075027\n",
       "Constructor recent points     0.061198\n",
       "Driver identity               0.056146\n",
       "Driver finish consistency     0.042868\n",
       "Grid position                 0.035511\n",
       "Other                         0.023078\n",
       "Constructor recent podiums    0.019216\n",
       "Driver recent podiums         0.014931\n",
       "Constructor identity          0.008771\n",
       "Name: importance, dtype: float64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def map_feature_group(f):\n",
    "    if f.startswith(\"driverId_\"):\n",
    "        return \"Driver identity\"\n",
    "    if f.startswith(\"constructorId_\"):\n",
    "        return \"Constructor identity\"\n",
    "    if f.startswith(\"circuitId_\"):\n",
    "        return \"Circuit\"\n",
    "    if f == \"grid\":\n",
    "        return \"Grid position\"\n",
    "    if f == \"qual_position\":\n",
    "        return \"Qualifying position\"\n",
    "    if f == \"driver_points_last3\":\n",
    "        return \"Driver recent points\"\n",
    "    if f == \"constructor_points_last3\":\n",
    "        return \"Constructor recent points\"\n",
    "    if f == \"driver_podiums_last3\":\n",
    "        return \"Driver recent podiums\"\n",
    "    if f == \"driver_finishpos_last3\":\n",
    "        return \"Driver finish consistency\"\n",
    "    if f == \"constructor_podiums_last3\":\n",
    "        return \"Constructor recent podiums\"\n",
    "    if f == \"grid_inverse\":\n",
    "        return \"Grid advantage (inverse)\"\n",
    "    return \"Other\"\n",
    "\n",
    "feature_importance_df[\"group\"] = feature_importance_df[\"feature\"].apply(map_feature_group)\n",
    "\n",
    "grouped_importance = (\n",
    "    feature_importance_df\n",
    "    .groupby(\"group\")[\"importance\"]\n",
    "    .sum()\n",
    "    .sort_values(ascending=False)\n",
    ")\n",
    "\n",
    "grouped_importance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "421bb6b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Driver form Signal\n",
    "def driver_form_signal(row):\n",
    "    if row[\"round\"] <= 3:\n",
    "        return \"UNKNOWN\"\n",
    "    if row[\"driver_points_last3\"] >= 18:\n",
    "        return \"STRONG\"\n",
    "    elif row[\"driver_points_last3\"] >= 8:\n",
    "        return \"MODERATE\"\n",
    "    else:\n",
    "        return \"WEAK\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "240cd659",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constructor momentum Signal\n",
    "def constructor_momentum_signal(row):\n",
    "    if row[\"round\"] <= 3:\n",
    "        return \"UNKNOWN\"\n",
    "    if row[\"constructor_podiums_last3\"] >= 0.5:\n",
    "        return \"HIGH\"\n",
    "    elif row[\"constructor_podiums_last3\"] >= 0.2:\n",
    "        return \"MEDIUM\"\n",
    "    else:\n",
    "        return \"LOW\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08032b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid advantage Signal\n",
    "def grid_advantage_signal(row):\n",
    "    if row[\"grid\"] <= 3:\n",
    "        return \"FRONT\"\n",
    "    elif row[\"grid\"] <= 10:\n",
    "        return \"MIDFIELD\"\n",
    "    else:\n",
    "        return \"BACK\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc07fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Driver consistency Signal\n",
    "def consistency_signal(row):\n",
    "    if row[\"round\"] <= 3:\n",
    "        return \"UNKNOWN\"\n",
    "    if row[\"driver_finishpos_last3\"] <= 4:\n",
    "        return \"HIGH\"\n",
    "    elif row[\"driver_finishpos_last3\"] <= 9:\n",
    "        return \"MEDIUM\"\n",
    "    else:\n",
    "        return \"LOW\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "325c656b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_signals(row):\n",
    "    return {\n",
    "        \"driver_form\": driver_form_signal(row),\n",
    "        \"constructor_momentum\": constructor_momentum_signal(row),\n",
    "        \"grid_positioning\": grid_advantage_signal(row),\n",
    "        \"consistency\": consistency_signal(row)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "eef7f47f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "season                           2022\n",
       "round                               1\n",
       "circuitId                     bahrain\n",
       "driverId                       bottas\n",
       "constructorId                    alfa\n",
       "grid                                6\n",
       "qual_position                     6.0\n",
       "driver_points_last3               0.0\n",
       "constructor_points_last3          0.0\n",
       "driver_podiums_last3              0.0\n",
       "driver_finishpos_last3            0.0\n",
       "constructor_podiums_last3         0.0\n",
       "grid_inverse                 0.166667\n",
       "podium                              0\n",
       "Name: 5, dtype: object"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample for signal extraction\n",
    "df_feat.iloc[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ea938c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "season                                 2023\n",
       "round                                    10\n",
       "circuitId                       silverstone\n",
       "driverId                     max_verstappen\n",
       "constructorId                      red_bull\n",
       "grid                                      1\n",
       "qual_position                           1.0\n",
       "driver_points_last3               25.666667\n",
       "constructor_points_last3          16.666667\n",
       "driver_podiums_last3                    1.0\n",
       "driver_finishpos_last3                  1.0\n",
       "constructor_podiums_last3          0.666667\n",
       "grid_inverse                            1.0\n",
       "podium                                    1\n",
       "Name: 620, dtype: object"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mid season row testing\n",
    "df_feat[(df_feat[\"season\"] == 2023) & (df_feat[\"round\"] == 10)].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "763691d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_signal_pack(row, podium_proba: float, threshold: float = 0.30):\n",
    "    # row can be a pandas Series\n",
    "    signals = {\n",
    "        \"driver_form\": driver_form_signal(row),\n",
    "        \"constructor_momentum\": constructor_momentum_signal(row),\n",
    "        \"grid_positioning\": grid_advantage_signal(row),\n",
    "        \"consistency\": consistency_signal(row),\n",
    "    }\n",
    "\n",
    "    facts = {\n",
    "        \"season\": int(row[\"season\"]),\n",
    "        \"round\": int(row[\"round\"]),\n",
    "        \"circuitId\": str(row[\"circuitId\"]),\n",
    "        \"driverId\": str(row[\"driverId\"]),\n",
    "        \"constructorId\": str(row[\"constructorId\"]),\n",
    "        \"grid\": int(row[\"grid\"]),\n",
    "        \"qual_position\": int(float(row[\"qual_position\"])),\n",
    "        \"driver_points_last3\": float(row[\"driver_points_last3\"]),\n",
    "        \"constructor_points_last3\": float(row[\"constructor_points_last3\"]),\n",
    "        \"driver_podiums_last3\": float(row[\"driver_podiums_last3\"]),\n",
    "        \"driver_finishpos_last3\": float(row[\"driver_finishpos_last3\"]),\n",
    "        \"constructor_podiums_last3\": float(row[\"constructor_podiums_last3\"]),\n",
    "    }\n",
    "\n",
    "    decision = \"PODIUM_LIKELY\" if podium_proba >= threshold else \"PODIUM_UNLIKELY\"\n",
    "\n",
    "    return {\n",
    "        \"podium_probability\": float(podium_proba),\n",
    "        \"decision_threshold\": float(threshold),\n",
    "        \"decision\": decision,\n",
    "        \"signals\": signals,\n",
    "        \"facts\": facts,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "375d60e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def make_llm_prompt(signal_pack: dict) -> str:\n",
    "    return f\"\"\"\n",
    "You are generating a short Formula 1 race prediction explanation for a user.\n",
    "\n",
    "Rules:\n",
    "- Use ONLY the provided JSON information.\n",
    "- Do NOT invent driver traits, weather, tyre strategy, or real-world events.\n",
    "- If some signals are UNKNOWN, mention that it is early-season or limited recent data.\n",
    "- Output must be 3-5 sentences, clear and descriptive, not bullet points.\n",
    "\n",
    "JSON:\n",
    "{json.dumps(signal_pack, indent=2)}\n",
    "\n",
    "Write the explanation now.\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f7df78bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are generating a short Formula 1 race prediction explanation for a user.\n",
      "\n",
      "Rules:\n",
      "- Use ONLY the provided JSON information.\n",
      "- Do NOT invent driver traits, weather, tyre strategy, or real-world events.\n",
      "- If some signals are UNKNOWN, mention that it is early-season or limited recent data.\n",
      "- Output must be 3-5 sentences, clear and descriptive, not bullet points.\n",
      "\n",
      "JSON:\n",
      "{\n",
      "  \"podium_probability\": 0.87,\n",
      "  \"decision_threshold\": 0.3,\n",
      "  \"decision\": \"PODIUM_LIKELY\",\n",
      "  \"signals\": {\n",
      "    \"driver_form\": \"STRONG\",\n",
      "    \"constructor_momentum\": \"HIGH\",\n",
      "    \"grid_positioning\": \"FRONT\",\n",
      "    \"consistency\": \"HIGH\"\n",
      "  },\n",
      "  \"facts\": {\n",
      "    \"season\": 2023,\n",
      "    \"round\": 10,\n",
      "    \"circuitId\": \"silverstone\",\n",
      "    \"driverId\": \"max_verstappen\",\n",
      "    \"constructorId\": \"red_bull\",\n",
      "    \"grid\": 1,\n",
      "    \"qual_position\": 1,\n",
      "    \"driver_points_last3\": 25.666666666666668,\n",
      "    \"constructor_points_last3\": 16.666666666666668,\n",
      "    \"driver_podiums_last3\": 1.0,\n",
      "    \"driver_finishpos_last3\": 1.0,\n",
      "    \"constructor_podiums_last3\": 0.6666666666666666\n",
      "  }\n",
      "}\n",
      "\n",
      "Write the explanation now.\n"
     ]
    }
   ],
   "source": [
    "row = df_feat[(df_feat[\"season\"] == 2023) & (df_feat[\"round\"] == 10)].iloc[0]\n",
    "\n",
    "# Example: pretend your model predicted 0.87\n",
    "signal_pack = build_signal_pack(row, podium_proba=0.87, threshold=0.30)\n",
    "prompt = make_llm_prompt(signal_pack)\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f2d6f853",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fallback_explanation(signal_pack: dict) -> str:\n",
    "    s = signal_pack[\"signals\"]\n",
    "    f = signal_pack[\"facts\"]\n",
    "    p = signal_pack[\"podium_probability\"]\n",
    "\n",
    "    parts = []\n",
    "    parts.append(f\"For {f['driverId']} at {f['circuitId']}, the model estimates a podium probability of {p:.2f}.\")\n",
    "    parts.append(f\"Starting position signals are {s['grid_positioning']} (grid {f['grid']}, qualifying {f['qual_position']}).\")\n",
    "    parts.append(f\"Recent form is {s['driver_form']} and consistency is {s['consistency']}, with constructor momentum {s['constructor_momentum']}.\")\n",
    "    parts.append(f\"Overall decision: {signal_pack['decision'].replace('_', ' ').lower()} based on these indicators.\")\n",
    "    return \" \".join(parts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7ad808b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max_verstappen at silverstone, the model estimates a podium probability of 0.87. Starting position signals are FRONT (grid 1, qualifying 1). Recent form is STRONG and consistency is HIGH, with constructor momentum HIGH. Overall decision: podium likely based on these indicators.\n"
     ]
    }
   ],
   "source": [
    "print(fallback_explanation(signal_pack))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "de45ede1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_prediction_output(row, podium_proba, threshold=0.30):\n",
    "\n",
    "    signals = {\n",
    "        \"driver_form\": driver_form_signal(row),\n",
    "        \"constructor_momentum\": constructor_momentum_signal(row),\n",
    "        \"grid_positioning\": grid_advantage_signal(row),\n",
    "        \"consistency\": consistency_signal(row),\n",
    "    }\n",
    "\n",
    "    decision = \"PODIUM_LIKELY\" if podium_proba >= threshold else \"PODIUM_UNLIKELY\"\n",
    "\n",
    "    # Confidence logic (VERY useful for UI)\n",
    "    if podium_proba >= 0.75 or podium_proba <= 0.15:\n",
    "        confidence = \"HIGH\"\n",
    "    elif podium_proba >= 0.55 or podium_proba <= 0.30:\n",
    "        confidence = \"MEDIUM\"\n",
    "    else:\n",
    "        confidence = \"LOW\"\n",
    "\n",
    "    facts = {\n",
    "        \"grid\": int(row[\"grid\"]),\n",
    "        \"qual_position\": int(float(row[\"qual_position\"])),\n",
    "        \"driver_points_last3\": float(row[\"driver_points_last3\"]),\n",
    "        \"constructor_points_last3\": float(row[\"constructor_points_last3\"]),\n",
    "        \"driver_podiums_last3\": float(row[\"driver_podiums_last3\"]),\n",
    "        \"driver_finishpos_last3\": float(row[\"driver_finishpos_last3\"]),\n",
    "        \"constructor_podiums_last3\": float(row[\"constructor_podiums_last3\"]),\n",
    "    }\n",
    "\n",
    "    reasons = []\n",
    "\n",
    "    if signals[\"grid_positioning\"] == \"FRONT\":\n",
    "        reasons.append(\"strong starting position advantage\")\n",
    "\n",
    "    if signals[\"driver_form\"] == \"STRONG\":\n",
    "        reasons.append(\"strong recent driver performance\")\n",
    "\n",
    "    if signals[\"constructor_momentum\"] == \"HIGH\":\n",
    "        reasons.append(\"strong recent constructor momentum\")\n",
    "\n",
    "    if signals[\"consistency\"] == \"HIGH\":\n",
    "        reasons.append(\"high recent finishing consistency\")\n",
    "\n",
    "    if not reasons:\n",
    "        reasons.append(\"no strong performance signals detected\")\n",
    "\n",
    "    summary = (\n",
    "        f\"Podium probability {podium_proba:.2f}. \"\n",
    "        f\"Driver form {signals['driver_form']}, \"\n",
    "        f\"constructor momentum {signals['constructor_momentum']}, \"\n",
    "        f\"grid positioning {signals['grid_positioning']}, \"\n",
    "        f\"consistency {signals['consistency']}.\"\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        \"probability\": float(podium_proba),\n",
    "        \"decision\": decision,\n",
    "        \"confidence_level\": confidence,\n",
    "        \"signals\": signals,\n",
    "        \"facts\": facts,\n",
    "        \"reasons\": reasons,\n",
    "        \"summary\": summary,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "822222a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"probability\": 0.87,\n",
      "  \"decision\": \"PODIUM_LIKELY\",\n",
      "  \"confidence_level\": \"HIGH\",\n",
      "  \"signals\": {\n",
      "    \"driver_form\": \"STRONG\",\n",
      "    \"constructor_momentum\": \"HIGH\",\n",
      "    \"grid_positioning\": \"FRONT\",\n",
      "    \"consistency\": \"HIGH\"\n",
      "  },\n",
      "  \"facts\": {\n",
      "    \"grid\": 1,\n",
      "    \"qual_position\": 1,\n",
      "    \"driver_points_last3\": 25.666666666666668,\n",
      "    \"constructor_points_last3\": 16.666666666666668,\n",
      "    \"driver_podiums_last3\": 1.0,\n",
      "    \"driver_finishpos_last3\": 1.0,\n",
      "    \"constructor_podiums_last3\": 0.6666666666666666\n",
      "  },\n",
      "  \"reasons\": [\n",
      "    \"strong starting position advantage\",\n",
      "    \"strong recent driver performance\",\n",
      "    \"strong recent constructor momentum\",\n",
      "    \"high recent finishing consistency\"\n",
      "  ],\n",
      "  \"summary\": \"Podium probability 0.87. Driver form STRONG, constructor momentum HIGH, grid positioning FRONT, consistency HIGH.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "row = df_feat[(df_feat[\"season\"] == 2023) & (df_feat[\"round\"] == 10)].iloc[0]\n",
    "\n",
    "podium_proba = 0.87   # normally from model.predict_proba()\n",
    "\n",
    "output = generate_prediction_output(row, podium_proba)\n",
    "\n",
    "import json\n",
    "print(json.dumps(output, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034b5784",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# LLM prompt builder\n",
    "def build_llm_prompt(pred_output: dict) -> str:\n",
    "    return f\"\"\"\n",
    "You are an assistant that writes a short Formula 1 podium prediction explanation.\n",
    "\n",
    "Rules:\n",
    "- Use ONLY the information in the JSON.\n",
    "- Do NOT invent weather, tyre strategy, crashes, penalties, team orders, or driver personality traits.\n",
    "- Keep it 3–5 sentences.\n",
    "- Mention the decision, probability, confidence level, and 2–4 reasons.\n",
    "- If signals contain UNKNOWN, say limited recent data is available.\n",
    "\n",
    "JSON:\n",
    "{json.dumps(pred_output, indent=2)}\n",
    "\n",
    "Write the explanation now.\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f824b67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plug-in Interface\n",
    "def add_llm_explanation(pred_output: dict, llm_generate_fn) -> dict:\n",
    "    \"\"\"\n",
    "    llm_generate_fn: function(prompt: str) -> str\n",
    "    \"\"\"\n",
    "    prompt = build_llm_prompt(pred_output)\n",
    "    text = llm_generate_fn(prompt).strip()\n",
    "    pred_output = dict(pred_output)  # copy\n",
    "    pred_output[\"llm_explanation\"] = text\n",
    "    pred_output[\"llm_prompt_used\"] = prompt  # optional: keep for debugging\n",
    "    return pred_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c90e3458",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mock explanation: This driver shows strong indicators based on the provided signals and recent performance metrics.\n"
     ]
    }
   ],
   "source": [
    "def mock_llm(prompt: str) -> str:\n",
    "    # Very basic mock: pulls from JSON in the prompt? We'll just return a placeholder.\n",
    "    return \"Mock explanation: This driver shows strong indicators based on the provided signals and recent performance metrics.\"\n",
    "\n",
    "output_with_text = add_llm_explanation(output, mock_llm)\n",
    "print(output_with_text[\"llm_explanation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "3d944bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Later for connecting to real LLM API (e.g. OpenAI, Azure, etc.)\n",
    "def real_llm(prompt: str) -> str:\n",
    "    # TODO: call your chosen LLM provider here and return the generated text\n",
    "    # return response_text\n",
    "    raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "9a9c5640",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_llm_text(text: str) -> str:\n",
    "    banned = [\"weather\", \"rain\", \"crash\", \"penalty\", \"pit\", \"tyre\", \"safety car\"]\n",
    "    lower = text.lower()\n",
    "    if any(b in lower for b in banned):\n",
    "        # fallback to deterministic summary\n",
    "        return None\n",
    "    return text\n",
    "\n",
    "def add_llm_explanation_safe(pred_output: dict, llm_generate_fn) -> dict:\n",
    "    prompt = build_llm_prompt(pred_output)\n",
    "    text = llm_generate_fn(prompt).strip()\n",
    "    valid = validate_llm_text(text)\n",
    "    pred_output = dict(pred_output)\n",
    "    pred_output[\"llm_explanation\"] = valid if valid else pred_output[\"summary\"]\n",
    "    return pred_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d563d540",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.DataFrame([row.drop(\"podium\").to_dict()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "542ad49b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
